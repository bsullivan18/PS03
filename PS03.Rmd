---
title: 'STAT/MATH 495: Problem Set 03'
author: "Brenna Sullivan"
date: "17-09-26"
output:
  html_document:
    collapsed: no
    smooth_scroll: no
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5)
library(mosaic)
library(broom)
# Load packages
library(tidyverse)
library(plyr)
data1 <- read_csv("data/data1.csv")
data2 <- read_csv("data/data2.csv")
```


# Question

For both `data1` and `data2` tibbles (a tibble is a data frame with some
[metadata](https://blog.rstudio.com/2016/03/24/tibble-1-0-0#tibbles-vs-data-frames) attached:

* Find the splines model with the best out-of-sample predictive ability.
* Create a visualizaztion arguing why you chose this particular model.
* Create a visualizaztion of this model plotted over the given $(x_i, y_i)$ points for $i=1,\ldots,n=3000$.
* Give your estimate $\widehat{\sigma}$ of $\sigma$ where the noise component $\epsilon_i$ is distributed with mean 0 and  standard deviation $\sigma$.


# Cross Validation Function

In order to get the splines model with the best out of sample predictive ability for any data, you must create a function that takes in a test set and a training set and then gives the degrees of freedom that corresponds to the degrees of freedom as output.  Here, I have the RMSE calculated by taking the differences between the splines model values and the actual data values, averaging them, and then taking the square root.
```{r}
#test to delete
crossval <- function(train, test){
  dfRMSE <- data.frame()
  output <- NULL
  i <- 5
  while(i <= 50){
    model <- smooth.spline(x = train$x,y = train$y, df=i)
    new_x <- test$x
    output <- predict(model, new_x)
    output <- as.data.frame(output)
    output <- cbind(output, test$y)
    RMSE <- sqrt(mean(test$y - output$y)^2)
    new_row <- c(i, RMSE)
    dfRMSE <- rbind(dfRMSE, new_row)
    i = i + 1
  }
  names(dfRMSE) <- c("df","RMSE")
  return(dfRMSE)
}
```


# Data1

###Five Folds
Next, I split the data into 5 distinct groups with 20% of the data in each group.  This creates the folds that will become the test and training sets of the data when they are inputted into the crossvalidation function.
```{r}
#create the folds
set.seed(2)
splitdata <- sample(1:5, size = nrow(data1), replace=T, prob=c(0.2,0.2,0.2,0.2,0.2))
data11 <- data1[splitdata==1,]
data12 <- data1[splitdata==2,]
data13 <- data1[splitdata==3,]
data14 <- data1[splitdata==4,]
data15 <- data1[splitdata==5,]

#run each fold agains the other folds
fold1_d1 <- crossval(data1[splitdata != 1,], data11)
fold2_d1 <- crossval(data1[splitdata != 2,], data12)
fold3_d1 <- crossval(data1[splitdata != 3,], data13)
fold4_d1 <- crossval(data1[splitdata != 4,], data14)
fold5_d1 <- crossval(data1[splitdata != 5,], data15)
```

###meanRMSE

Next, the RMSE is calculated by taking the average of the values from each fold.
```{r}
#calculate the RMSE for each fold and take the average of the 5 to hey meanRMSE
data1_folds <- join_all(list(fold1_d1, fold2_d1, fold3_d1, fold4_d1, fold5_d1), by = "df")
names(data1_folds) <- c("df","fold1","fold2","fold3","fold4","fold5")
data1_folds$meanRMSE <- (data1_folds$fold1 + data1_folds$fold2 + data1_folds$fold3 + data1_folds$fold4 + data1_folds$fold5)/5
```


###Best Out-Of-Sample Predictive Ability
Next, I have plotted the values of the RMSE, which shows the minumum value of the RMSE and the coresponding degrees of freedom.
```{r}
#minimum point and graph of df
bestdf1 <- data1_folds[which(data1_folds$meanRMSE == min(data1_folds$meanRMSE)),]
bestdf1


ggplot() +
  geom_line(data = data1_folds, aes(x = df, y = meanRMSE))
  
```

Here, from the calculation of the minimum of the RMSE, as well as the graph, you can see that RMSE is the smallest when df=38.  There, the RMSE, which is the estimate $\widehat{\sigma}$, is .8610.

###Spline Model for Visualization

This, now, shows the splines model with the optimal degrees of freedom. 
```{r}
#spline model with the optimal degrees of freedom
data1_spline <- smooth.spline(data1$x, data1$y, df=bestdf1$df)


model_spline_data_frame <- data1_spline %>%
  broom::augment()
ggplot(model_spline_data_frame, aes(x=x)) +
  geom_point(aes(y=y)) +
  geom_line(aes(y=.fitted), col="blue", size=1)
```


# Data 2

###Five Folds
Next, I split the data into 5 distinct groups with 20% of the data in each group.  This creates the folds that will become the test and training sets of the data when they are inputted into the crossvalidation function.
```{r}
#create the folds
set.seed(2)
splitdata <- sample(1:5, size = nrow(data2), replace=T, prob=c(0.2,0.2,0.2,0.2,0.2))
data21 <- data2[splitdata==1,]
data22 <- data2[splitdata==2,]
data23 <- data2[splitdata==3,]
data24 <- data2[splitdata==4,]
data25 <- data2[splitdata==5,]

#run each fold agains the other folds
fold1_d2 <- crossval(data2[splitdata != 1,], data21)
fold2_d2 <- crossval(data2[splitdata != 2,], data22)
fold3_d2 <- crossval(data2[splitdata != 3,], data23)
fold4_d2 <- crossval(data2[splitdata != 4,], data24)
fold5_d2 <- crossval(data2[splitdata != 5,], data25)
```

###meanRMSE
Next, the RMSE is calculated by taking the average of the values from each fold.
```{r}
#calculate the RMSE for each fold and take the average of the 5 to get meanRMSE
data2_folds <- join_all(list(fold1_d2, fold2_d2, fold3_d2, fold4_d2, fold5_d2), by = "df")
names(data2_folds) <- c("df","fold1","fold2","fold3","fold4","fold5")
data2_folds$meanRMSE <- (data2_folds$fold1 + data2_folds$fold2 + data2_folds$fold3 + data2_folds$fold4 + data2_folds$fold5)/5
```


###Best Out-Of-Sample Predictive Ability
Next, I have plotted the values of the RMSE, which shows the minumum value of the RMSE and the coresponding degrees of freedom.
```{r}
#minimum point and graph of df
bestdf2 <- data2_folds[which(data2_folds$meanRMSE == min(data2_folds$meanRMSE)),]
bestdf2


ggplot() +
  geom_line(data = data2_folds, aes(x = df, y = meanRMSE))
  
```

Here, from the calculation of the minimum of the RMSE, as well as the graph, you can see that RMSE is the smallest when df=14.  There, the RMSE, which is the estimate $\widehat{\sigma}$, is 1.386.

###Spline Model for Visualization

This, now, shows the splines model with the optimal degrees of freedom. 
```{r}
#spline model with the optimal degrees of freedom
data2_spline <- smooth.spline(data2$x, data2$y, df=bestdf2$df)


model_spline_data_frame <- data1_spline %>%
  broom::augment()
ggplot(model_spline_data_frame, aes(x=x)) +
  geom_point(aes(y=y)) +
  geom_line(aes(y=.fitted), col="blue", size=1)
```

